{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**----------HECTOR_________HNM**"
      ],
      "metadata": {
        "id": "1gUK1USQake1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Install Required Libraries\n"
      ],
      "metadata": {
        "id": "7fod3Q9zDcI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai PyMuPDF tiktoken\n"
      ],
      "metadata": {
        "id": "5D6lMv0qDZGs",
        "outputId": "ea43a6d8-1146-4c1a-c867-86ef5e08a97e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, tiktoken\n",
            "Successfully installed PyMuPDF-1.25.3 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Extract Text from the PDF**\n",
        "\n",
        "Use the PyMuPDF library to extract text from the PDF:"
      ],
      "metadata": {
        "id": "eDErECOvDkyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extract text from a PDF file.\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# Example usage:\n",
        "pdf_path = '/content/sample-research-proposal.pdf'\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n"
      ],
      "metadata": {
        "id": "ydAh9LTfDgU8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Split Text into Manageable Chunks**\n",
        "\n",
        "Given GPT-4's token limitations, it's essential to split the text into chunks that fit within these constraints. We'll use the tiktoken library to handle tokenization:"
      ],
      "metadata": {
        "id": "-6h3IUbiDzks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def split_text_into_chunks(text, max_tokens=2000, model_name=\"gpt-4\"):\n",
        "    \"\"\"Split text into chunks based on token limits.\"\"\"\n",
        "    tokenizer = tiktoken.encoding_for_model(model_name)\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        token_length = len(tokenizer.encode(word)) + 1  # +1 for the space\n",
        "        if current_length + token_length > max_tokens:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_length = token_length\n",
        "        else:\n",
        "            current_chunk.append(word)\n",
        "            current_length += token_length\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Split the extracted text into chunks\n",
        "chunks = split_text_into_chunks(pdf_text)\n"
      ],
      "metadata": {
        "id": "Prni1EZwDr4r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Up OpenAI API**\n",
        "\n",
        "\n",
        "Configure the OpenAI API with your API key:"
      ],
      "metadata": {
        "id": "2V6d1bhOEA_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Set your OpenAI API key\n",
        "openai.api_key = 'API_KEY_Open_AI'\n"
      ],
      "metadata": {
        "id": "usxs5PdHEFeM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Custom Prompt**\n",
        "\n",
        "\n",
        "a comprehensive prompt to guide GPT-4 in generating detailed summaries with chain-of-thought reasoning:\n"
      ],
      "metadata": {
        "id": "ClFAiU78EOoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"\"\"\n",
        "You are an expert summarizer with a deep understanding of complex documents. Given the following passage, provide a clear, concise, and well-structured summary. Ensure the summary includes:\n",
        "\n",
        "- **Objectives:** The main goals or purposes outlined.\n",
        "- **Methodology:** The approaches and methods employed.\n",
        "- **Key Findings:** The primary results or discoveries.\n",
        "- **Conclusions:** The interpretations and implications.\n",
        "- **Recommendations:** Suggested actions or next steps.\n",
        "\n",
        "Additionally, incorporate chain-of-thought reasoning to elucidate the logical flow and connections between different sections of the document.\n",
        "\n",
        "Passage:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "3CxSzIZ6EJXU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Summarize Each Chunk**\n",
        "\n",
        "Iterate over each chunk, apply the custom prompt, and generate summaries:"
      ],
      "metadata": {
        "id": "pTmcUBfvEfOL"
      }
    },
    {
      "source": [
        "def summarize_chunk(chunk, prompt):\n",
        "    \"\"\"Summarize a text chunk using OpenAI's GPT-4.\"\"\"\n",
        "    # Initialize the OpenAI client, passing the API key\n",
        "    client = openai.OpenAI(api_key='paste_Your_API') # Pass the API key to the OpenAI client\n",
        "\n",
        "    # Call the API using the client object\n",
        "    response = client.chat.completions.create( # with client.chat.completions.create().\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt + chunk}\n",
        "        ],\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response.choices[0].message['content'].strip()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5w4ZY9ivFxe7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combine Chunk Summaries into a Final Summary**\n",
        "\n",
        "Merge the individual chunk summaries and generate a comprehensive final summary:"
      ],
      "metadata": {
        "id": "M76A-7wwEtg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store chunk summaries\n",
        "chunk_summaries = []\n",
        "\n",
        "# Iterate over the chunks and generate summaries for each chunk\n",
        "for chunk in chunks:\n",
        "    summary = summarize_chunk(chunk, custom_prompt)\n",
        "    chunk_summaries.append(summary)\n",
        "\n",
        "# Combine all chunk summaries\n",
        "combined_summary_text = \"\\n\\n\".join(chunk_summaries)\n"
      ],
      "metadata": {
        "id": "oQBl9slJGmhM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "source": [
        "def summarize_chunk(chunk, prompt):\n",
        "    \"\"\"Summarize a text chunk using OpenAI's GPT-4.\"\"\"\n",
        "    # Initialize the OpenAI client, passing the API key\n",
        "    client = openai.OpenAI(api_key='PASTE YOUR API') # Pass the API key to the OpenAI client\n",
        "\n",
        "    # Call the API using the client object\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt + chunk}\n",
        "        ],\n",
        "        max_tokens=500,\n",
        "        temperature=0.7\n",
        "    )\n",
        "    # Access content using .message.content\n",
        "    return response.choices[0].message.content.strip() # Access the content attribute of the ChatCompletionMessage object"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RXND08wcG12z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate a final cohesive summary\n",
        "final_summary_prompt = \"\"\"\n",
        "You have been provided with summaries of different sections of a document. Your task is to integrate these summaries into a single, coherent, and well-structured summary. Ensure that the final summary maintains logical flow and effectively synthesizes the information from all sections.\n",
        "\n",
        "Section Summaries:\n",
        "\"\"\"\n",
        "\n",
        "final_summary = summarize_chunk(combined_summary_text, final_summary_prompt)\n",
        "\n",
        "# Display the final summary\n",
        "print(\"Final Document Summary:\\n\")\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "id": "mNjh_iMuEcIs",
        "outputId": "5ba3b16e-2048-4b88-bb84-f2c4b103ed64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Document Summary:\n",
            "\n",
            "The integrated summary of the sections is as follows:\n",
            "\n",
            "The various research proposals aim to elucidate the experiences and perceptions of different societal groups, focusing on working-class fathers post-divorce/separation, the changing perception of 'the people' in social welfare, and the shift in policing towards a consumer-based approach.\n",
            "\n",
            "In the first two studies, the main goal is to explore the experiences of fathers after divorce/separation and their negotiation of fatherhood roles and work-life balance. The methodologies in these studies are primarily qualitative, employing methods such as semi-structured interviews, participant observation, and reflexive interviewing. The studies anticipate providing a nuanced understanding of post-divorce/separation fatherhood and its broader social and political significance, as well as informing more appropriate and egalitarian social policy. Recommendations include further research into these experiences and deeper engagement with the data and existing literature.\n",
            "\n",
            "The latter proposals aim to explore the shift from police to policing and the development of consumerist relations in this field. The research will use ethnographic methodology, combining in-depth qualitative approaches and focus group discussions. These studies plan to investigate the interrelationships between policing structures, the state, and 'the people' through restorative justice practices. The anticipated outcomes include insights into recent reforms in policing and the complex tensions within various tiers in the apparatus of police government.\n",
            "\n",
            "A common thread across the studies is the potential to challenge traditional roles and norms, whether in fatherhood post-divorce/separation or in policing. The research approaches are exploratory and aim to uncover insights that could have significant sociopolitical implications and inform future policy-making. All proposals emphasize maintaining ethical standards throughout the research process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "\n",
        "\n",
        "**Token Management**: Adjust the max_tokens parameter based on GPT-4's limitations to ensure the model processes the input effectively.\n",
        "\n",
        "\n",
        "**Prompt Customization:** Tailor the custom_prompt to align with the specific content and desired focus of your documents.\n",
        "\n",
        "**API Costs**: Be mindful of the costs associated with OpenAI API usage, especially when processing large documents."
      ],
      "metadata": {
        "id": "xZlIaokeE6eD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1g1rh7YWE6Kt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}